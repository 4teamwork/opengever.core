#!/usr/bin/env python
"""A concurrent wrapper for timing xmltestrunner tests for opengever.core."""
from __future__ import print_function
from argparse import ArgumentParser
from collections import OrderedDict
from fnmatch import fnmatch
from logging import DEBUG
from logging import Formatter
from logging import getLogger
from logging import INFO
from logging import StreamHandler
from logging.handlers import MemoryHandler
from multiprocessing import cpu_count
from multiprocessing import Pool
from os import environ
from os import killpg
from os import path
from os import setpgrp
from os import unlink
from os import walk
from signal import SIGINT
from signal import SIGKILL
from signal import signal
from subprocess import check_output
from subprocess import PIPE
from subprocess import Popen
from time import sleep
from time import time
import locale
import sys


def humanize_time(seconds):
    """Humanize a seconds based delta time.

    Only handles time spans up to weeks for simplicity.
    """
    minutes, seconds = divmod(seconds, 60)
    hours, minutes = divmod(minutes, 60)
    days, hours = divmod(hours, 24)
    weeks, days = divmod(days, 7)

    seconds = int(seconds)
    minutes = int(minutes)
    hours = int(hours)
    days = int(days)
    weeks = int(weeks)

    output = []

    if weeks:
        output.append('{:02d} weeks'.format(weeks))
    if days:
        output.append('{:02d} days'.format(days))
    if hours:
        output.append('{:02d} hours'.format(hours))
    if minutes:
        output.append('{:02d} minutes'.format(minutes))

    output.append('{:02d} seconds'.format(seconds))

    return ' '.join(output)


def setup_termination():
    # Set the group flag so that subprocesses will be in the same group.
    setpgrp()

    def terminate(signum, frame):
        # Kill the group (including main process) on terminal signal.
        killpg(0, SIGKILL)

    signal(SIGINT, terminate)


def get_concurrency():
    # Counter system congestion and hyperthreading, FWIW
    concurrency = cpu_count() // 2 - 1

    # Make sure we use at least one core
    if concurrency < 1:
        concurrency = 1

    return concurrency


def discover_test_layers():
    logger.info('Discovering test classes')

    test_classes_per_layer = {}
    current_layer = None

    output_encoding = sys.stdout.encoding
    if output_encoding is None:
        output_encoding = locale.getpreferredencoding()

    test_discovery = check_output(
        ('bin/test', '--list-tests', ),
        ).decode(output_encoding).splitlines()

    for result in test_discovery:
        is_layer_header = result.startswith('Listing')

        # We're guaranteed the output format so we can just set this
        if is_layer_header:
            current_layer = result.split()[1]
            test_classes_per_layer[current_layer] = []

        # There are unrelated lines in the beginning we do not want to catch
        if current_layer and not is_layer_header:
            test_classes_per_layer[current_layer].append(
                result.split()[-1].strip('()'),
                )

    # Prune to unique test classes per layer
    return {
        layer: tuple(sorted(set(tests)))
        for layer, tests in test_classes_per_layer.iteritems()
        }


def create_test_run_params():
    test_classes_per_layer = discover_test_layers()

    # Ordered by hand for a sensible run order
    # The order is used below for ordering the test run
    layers_to_split = OrderedDict()
    layers_to_split[u'opengever.core.testing.MeetingLayer'] = 1
    layers_to_split[u'opengever.core.testing.opengever.core:integration'] = 2
    layers_to_split[u'opengever.core.testing.opengever.core:functional'] = 8

    # The common grouping for all the small / quick layers
    test_run_params = [{
        'layers': [],
        'test_classes': [],
        'batch': '1 / 1',
        }]

    for layer, test_classes in test_classes_per_layer.iteritems():
        if layer in layers_to_split:
            n = layers_to_split.get(layer)
            test_class_groups = [test_classes[i::n] for i in range(n)]
            test_class_group_count = len(test_class_groups)
            for i, test_class_group in enumerate(test_class_groups):
                test_run_params.append({
                    'layers': [layer],
                    'test_classes': test_class_group,
                    'batch': '{} / {}'.format(i + 1, test_class_group_count)
                })
        else:
            test_run_params[0].get('layers').append(layer)
            test_run_params[0].get('test_classes').extend(test_classes)

    # Cement all the grouped layers
    for i, params in enumerate(test_run_params):
        params['layers'] = tuple(sorted(set(params['layers'])))
        params['test_classes'] = tuple(sorted(set(params['test_classes'])))
        params['port'] = i + 1

    # Make sure heavy stuff runs first - add light stuff on top
    for priority_layer in layers_to_split:
        for param in test_run_params:
            if priority_layer in param.get('layers'):
                test_run_params.insert(
                    0,
                    test_run_params.pop(test_run_params.index(param)),
                    )

    # Cement the test batches - reverse for proper ordering
    return tuple(reversed(test_run_params))


def remove_bytecode_files(directory_path):
    logger.info('Removing bytecode files from %s', directory_path)
    for filename in find_bytecode_files(directory_path):
        unlink(filename)


def find_bytecode_files(directory_path):
    for root, _, files in walk(directory_path):
        for name in files:
            if fnmatch(name, '*.py[co]'):
                yield path.join(root, name)


def run_tests(test_run_params):
    """Run and time 'bin/test --layer layer -m module [-m module]'.

    Return the module name, layer name and stderr.
    """
    params = ['bin/test']

    layers = test_run_params.get('layers')
    test_classes = test_run_params.get('test_classes')
    batch = test_run_params.get('batch')
    port = test_run_params.get('port')

    if layers:
        for layer in layers:
            params.append('--layer')
            params.append(layer)

    if test_classes:
        for test_class in test_classes:
            params.append('-t')
            params.append(test_class)

    printable_layers = ', '.join(layers)

    logger.debug(
        'Start: %s - %d test classes - batch %s',
        printable_layers,
        len(test_classes),
        batch,
        )

    env = environ.copy()
    env['ZSERVER_PORT'] = env.get('PORT{}'.format(port), str(55000 + port))

    start = time()

    process = Popen(
        params,
        env=env,
        stderr=PIPE,
        stdout=PIPE,
        )

    stdout, stderr = process.communicate()
    returncode = process.returncode

    runtime = time() - start

    result = {
        'layers': layers,
        'test_classes': test_classes,
        'batch': batch,
        'port': env.get('ZSERVER_PORT'),
        'returncode': returncode,
        'runtime': runtime,
        'stderr': stderr,
        'stdout': stdout,
        }

    logger.debug(
        'Done : %s - %d test classes - batch %s in %s at %.2fs / test class',
        printable_layers,
        len(test_classes),
        batch,
        humanize_time(runtime),
        runtime / len(test_classes),
        )

    return result


def handle_results(results):
    success = []
    runtime = 0

    # Set up a logger for writing output to stdout. We do this because
    # the logging module handles I/O encoding properly, whereas with 'print'
    # we'd need to do it ourselves. (Think piping the output of bin/mtest
    # somewhere, or shell I/O redirection).
    log_output = getLogger('mtest.output')
    log_output.propagate = False
    stdout_handler = StreamHandler(stream=sys.stdout)
    stdout_handler.setFormatter(Formatter(''))
    log_output.addHandler(stdout_handler)
    log_output.setLevel(INFO)

    while results:
        sleep(1)

        mature_indices = []
        mature_results = []

        for i, result in enumerate(results):
            if result.ready():
                mature_indices.append(i)
                # The enumeration index can be off for the .pop() otherwise
                break

        for i in mature_indices:
            mature_results.append(results.pop(i).get())

        for result in mature_results:
            # For some reason we get the test run result dict wrapped in a list
            returncode = result.get('returncode', 1)
            stderr = result.get('stderr')
            stdout = result.get('stdout')
            runtime += result.get('runtime')

            if not stderr and not returncode:
                success.append(True)

            else:
                success.append(False)
                log_output.info('')
                log_output.info('STDERR')
                log_output.info('')
                log_output.info(result.get('layers'))
                log_output.info('')
                log_output.info(stderr)
                log_output.info('')
                if returncode:
                    log_output.info('')
                    log_output.info('STDOUT')
                    log_output.info('')
                    log_output.info(result.get('layers'))
                    log_output.info('')
                    log_output.info(stdout)
                    log_output.info('')

    logger.debug(
        'Aggregate runtime %s.',
        humanize_time(runtime)
        )

    # Nothing returned False, everything went fine
    return all(r is True for r in success)


def main():
    """Discovers and times tests in parallel via multiprocessing.Pool()."""
    # Remove *.py[co] files to avoid race conditions with parallel workers
    # stepping on each other's toes when trying to clean up stale bytecode.
    #
    # Setting PYTHONDONTWRITEBYTECODE is not enough, because running buildout
    # also already precompiles bytecode for some eggs.
    logger.info('Cleaning bytecode files')
    remove_bytecode_files(OPENGEVER_PATH)
    remove_bytecode_files('src')

    test_run_params = create_test_run_params()

    start = time()

    logger.info('Running tests')

    pool = Pool(CONCURRENCY)
    results = [
        pool.apply_async(run_tests, (params, ))
        for params in test_run_params
        ]

    success = handle_results(results)

    pool.close()
    pool.join()

    logger.debug('Wallclock runtime %s.', humanize_time(time() - start))

    if success:
        logger.info('No failed tests.')
        return True

    return False


# Having the __main__ guard is necessary for multiprocessing.Pool().
if __name__ == '__main__':
    # Globals
    environ['PYTHONUNBUFFERED'] = '1'
    environ['PYTHONDONTWRITEBYTECODE'] = '1'

    DEBUG_MODE = False

    CONCURRENCY = int(environ.get('MTEST_PROCESSORS', get_concurrency()))

    BUILDOUT_PATH = path.abspath(path.join(__file__, '..', '..'))
    OPENGEVER_PATH = path.join(BUILDOUT_PATH, 'opengever')

    # CLI arguments
    parser = ArgumentParser(description='Run tests in parallel.')

    parser.add_argument(
        '-d',
        '--debug',
        help='Set the log level to debug.',
        action='store_true',
        )

    parser.add_argument(
        '-j',
        '--jobs',
        help='Set the testing concurrency level.',
        )

    args = parser.parse_args()

    if args.jobs:
        CONCURRENCY = int(args.jobs)

    if args.debug:
        DEBUG_MODE = True
        default_loglevel = DEBUG
    else:
        default_loglevel = INFO

    # Logging
    logger = getLogger('mtest')
    logger.setLevel(default_loglevel)

    # Set up logging to stdout
    stream_handler = StreamHandler()
    stream_handler.setLevel(default_loglevel)
    log_formatter = Formatter(
        ' - '.join((
            '%(asctime)s',
            '%(name)s',
            '%(levelname)s',
            '%(message)s',
            )),
        )
    stream_handler.setFormatter(log_formatter)

    # Buffer log messages so we do not get broken-by-racecondition
    # debug log lines in stdout
    memory_handler = MemoryHandler(
        4096,
        flushLevel=DEBUG,
        target=stream_handler,
        )
    memory_handler.setLevel(default_loglevel)

    logger.addHandler(memory_handler)

    setup_termination()

    if main():
        exit(0)

    exit(1)
