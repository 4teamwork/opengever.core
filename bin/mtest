#!/usr/bin/env python3

# Runs the tests in configurably many subprocesses.

from fnmatch import fnmatch
from random import shuffle

import concurrent.futures
import os
import os.path
import subprocess
import sys


os.environ['PYTHONDONTWRITEBYTECODE'] = '1'

PROCESSORS = int(os.environ.get('MTEST_PROCESSORS', '4'))

MAX_TEST_LAYER_SIZE = int(os.environ.get('MTEST_MAX_TEST_LAYER_SIZE', '500'))
TEST_CHUNK_SIZE = int(os.environ.get('MTEST_TEST_CHUNK_SIZE', '300'))

BUILDOUT_PATH = os.path.abspath(os.path.join(__file__, '..', '..'))
OPENGEVER_PATH = os.path.join(BUILDOUT_PATH, 'opengever')


def main():
    # Remove *.py[co] files to avoid race conditions with parallel workers
    # stepping on each other's toes when trying to clean up stale bytecode.
    #
    # Setting PYTHONDONTWRITEBYTECODE is not enough, because running buildout
    # also already precompiles bytecode for some eggs.
    remove_bytecode_files(OPENGEVER_PATH)
    remove_bytecode_files('src')

    print("Discovering tests.", flush=True)

    tests = subprocess.check_output(('bin/test', '--list')).decode('UTF-8')

    layers = [
        layer.split('\n') for layer in tests.split(':')
        if 'test_' in layer
        ]

    split_layers = []

    for layer in layers:
        # Split the layer if above the configured layer size limit
        if len(layer) > MAX_TEST_LAYER_SIZE:
            # Randomize test chunking within a layer
            shuffle(layer)
            # Split into configurable chunks
            chunks = [
                layer[i:i + TEST_CHUNK_SIZE]
                for i in range(0, len(layer), TEST_CHUNK_SIZE)
                ]

            for chunk in chunks:
                split_layers.append([
                    test.split(' ')[2] for test in chunk
                    if test.startswith('  test_')
                    ])

        else:
            split_layers.append([
                test.split(' ')[2] for test in layer
                if test.startswith('  test_')
                ])

    print("Running tests with {} processors.".format(PROCESSORS), flush=True)
    with concurrent.futures.ThreadPoolExecutor(max_workers=PROCESSORS) as executor:  # noqa
        outputs = executor.map(run_tests, split_layers)

    failed_tests = False
    for output in outputs:
        if output:
            failed_tests = True
            for line in output:
                # The output already has newlines from the testrunner
                print(line.decode('UTF-8'), end='', flush=True)

    if failed_tests:
        sys.exit(1)

    print("No failed tests.", flush=True)


def remove_bytecode_files(path):
    print("Removing bytecode files from {}".format(path), flush=True)
    for filename in find_bytecode_files(path):
        os.unlink(filename)


def find_bytecode_files(path):
    for root, dirs, files in os.walk(path):
        for name in files:
            if fnmatch(name, '*.py[co]'):
                yield os.path.join(root, name)


def run_tests(tests):
    arguments = ['bin/test']
    for test in tests:
        arguments.append('-t')
        arguments.append(test)

    test_run = subprocess.Popen(
        arguments,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        )

    test_run.wait()

    if test_run.returncode != 0:
        return test_run.stdout.readlines()
    return None


if __name__ == '__main__':
    main()
