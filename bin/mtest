#!/usr/bin/env python3

# Runs the tests in configurably many subprocesses.

from copy import copy
from fnmatch import fnmatch

import concurrent.futures
import os
import subprocess
import sys


os.environ['PYTHONDONTWRITEBYTECODE'] = '1'

PROCESSORS = int(os.environ.get('MTEST_PROCESSORS', '4'))

BUILDOUT_PATH = os.path.abspath(os.path.join(__file__, '..', '..'))
OPENGEVER_PATH = os.path.join(BUILDOUT_PATH, 'opengever')


def main():
    # Remove *.py[co] files to avoid race conditions with parallel workers
    # stepping on each other's toes when trying to clean up stale bytecode.
    #
    # Setting PYTHONDONTWRITEBYTECODE is not enough, because running buildout
    # also already precompiles bytecode for some eggs.
    remove_bytecode_files(OPENGEVER_PATH)
    remove_bytecode_files('src')

    print("Discovering modules.", flush=True)

    known_very_slow_modules = [
        'opengever.meeting',
    ]

    known_slow_modules = [
        'opengever.base',
        'opengever.document',
        'opengever.dossier',
        'opengever.task',
        ]

    modules = []
    for name in os.listdir('opengever'):
        if name[0].isalpha():
            complete_name = 'opengever.' + name
            if complete_name not in known_slow_modules:
                if complete_name not in known_very_slow_modules:
                    modules.append(complete_name)

    free_cores = PROCESSORS - len(known_very_slow_modules)

    if PROCESSORS == 1:
        # Just run everything sequentially in one job
        batches = known_very_slow_modules + known_slow_modules + modules

    elif free_cores > 0:
        # Create as many test batches as there are non-dedicated runners
        batches = [[] for n in range(free_cores)]

        # Round robin the known slow modules across the test runners
        for i, module in enumerate(known_slow_modules + modules):
            batches[i % free_cores].append(module)

        # Append the known very slow modules as their dedicated test runners
        for module in known_very_slow_modules:
            batches.append([module])

    else:
        # We can only run the dedicated very slow ones separate from the rest
        batches = []
        for module in known_very_slow_modules:
            batches.append(known_very_slow_modules)
        batches.append(modules)

    # Guard against empty batches in case of more processors than modules
    # Get worker ZSERVER_PORT from the jenkins port allocator
    # The jenkins port allocator enumerates starting from 1
    # Default to 55000 + i
    batches = [
        (os.environ.get('PORT{}'.format(i + 1), str(55000 + i)), batch)
        for i, batch in enumerate(batches)
        if batch
        ]

    print("Running tests with {} processors.".format(PROCESSORS), flush=True)
    with concurrent.futures.ProcessPoolExecutor(max_workers=PROCESSORS) as executor:  # noqa
        outputs = executor.map(run_tests, batches)

    failed_tests = False
    for output in outputs:
        if output:
            # This is a tuple of stdout and stderr as bytestrings
            for out in output:
                if out:
                    failed_tests = True
                    # This explicitly expects UTF-8 as the runtime locale!
                    print(out.decode('UTF-8'), end='', flush=True)

    if failed_tests:
        sys.exit(1)

    print("No failed tests.", flush=True)


def remove_bytecode_files(path):
    print("Removing bytecode files from {}".format(path), flush=True)
    for filename in find_bytecode_files(path):
        os.unlink(filename)


def find_bytecode_files(path):
    for root, dirs, files in os.walk(path):
        for name in files:
            if fnmatch(name, '*.py[co]'):
                yield os.path.join(root, name)


def run_tests(runtime_params):
    arguments = ['bin/test']
    for module in runtime_params[1]:
        arguments.append('-m')
        arguments.append(module)

    env = copy(os.environ)
    env['ZSERVER_PORT'] = runtime_params[0]

    test_run = subprocess.Popen(
        arguments,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        env=env,
        )

    # The pipe buffer is only 4k in size, so we need to constantly fetch it
    output = test_run.communicate()

    if test_run.returncode != 0:
        # Only return output if we have a failed test
        return output
    return None


if __name__ == '__main__':
    main()
