#!/usr/bin/env python
"""A concurrent wrapper for timing xmltestrunner tests for opengever.core."""
from __future__ import print_function
from argparse import ArgumentParser
from fnmatch import fnmatch
from logging import DEBUG
from logging import Formatter
from logging import getLogger
from logging import INFO
from logging import StreamHandler
from logging.handlers import MemoryHandler
from multiprocessing import cpu_count
from multiprocessing import Pool
from os import environ
from os import killpg
from os import path
from os import setpgrp
from os import unlink
from os import walk
from signal import SIGINT
from signal import SIGKILL
from signal import signal
from subprocess import PIPE
from subprocess import Popen
from time import time


def humanize_time(seconds):
    """Humanize a seconds based delta time.

    Only handles time spans up to weeks for simplicity.
    """
    minutes, seconds = divmod(seconds, 60)
    hours, minutes = divmod(minutes, 60)
    days, hours = divmod(hours, 24)
    weeks, days = divmod(days, 7)

    seconds = int(seconds)
    minutes = int(minutes)
    hours = int(hours)
    days = int(days)
    weeks = int(weeks)

    output = []

    if weeks:
        output.append('{:02d} weeks'.format(weeks))
    if days:
        output.append('{:02d} days'.format(days))
    if hours:
        output.append('{:02d} hours'.format(hours))
    if minutes:
        output.append('{:02d} minutes'.format(minutes))

    output.append('{:02d} seconds'.format(seconds))

    return ' '.join(output)


def setup_termination():
    # Set the group flag so that subprocesses will be in the same group.
    setpgrp()

    def terminate(signum, frame):
        # Kill the group (including main process) on terminal signal.
        killpg(0, SIGKILL)

    signal(SIGINT, terminate)


def get_concurrency():
    # Counter system congestion and hyperthreading, FWIW
    concurrency = cpu_count() // 2 - 1

    # Make sure we use at least one core
    if concurrency < 1:
        concurrency = 1

    return concurrency


def create_test_run_params():
    test_run_params = []

    # Manually ordered per metrification
    standalone_modules = (
        'opengever.document',
        'opengever.base',
        'opengever.task',
        'opengever.disposition',
        )

    # Manually ordered per metrification
    standalone_layers = (
        'opengever.core.testing.MeetingLayer',
        'opengever.core.testing.opengever.core:functional:zserver',
        'opengever.core.testing.opengever.core:integration',
        )

    if CONCURRENCY > 1:
        module_negation = tuple(
            ''.join(('!', module, ))
            for module in standalone_modules
            )

        layer_negation = tuple(
            ''.join(('!', layer, ))
            for layer in standalone_layers
            )

        for layer in standalone_layers:
            test_run_params.append({
                'layers': (layer, ),
                'modules': None,
                })

        test_run_params.append({
            'layers': layer_negation,
            'modules': module_negation,
            })

        for module in standalone_modules:
            test_run_params.append({
                'layers': layer_negation,
                'modules': (module, ),
                })

    else:
        test_run_params.append({
            'layers': None,
            'modules': None,
            })

    return tuple(test_run_params)


def remove_bytecode_files(directory_path):
    logger.info('Removing bytecode files from %s', directory_path)
    for filename in find_bytecode_files(directory_path):
        unlink(filename)


def find_bytecode_files(directory_path):
    for root, _, files in walk(directory_path):
        for name in files:
            if fnmatch(name, '*.py[co]'):
                yield path.join(root, name)


def run_tests(test_run_params):
    """Run and time 'bin/test --layer layer -m module [-m module]'.

    Return the module name, layer name and stderr.
    """
    params = ['bin/test']

    layers = test_run_params.get('layers', None)
    modules = test_run_params.get('modules', None)

    if layers:
        for layer in layers:
            params.append('--layer')
            params.append(layer)

    if modules:
        for module in modules:
            params.append('-m')
            params.append(module)

    logger.debug('Start: %s %s', layers, modules)

    # ZServer tests will be run separately of everything else per layer
    # separation
    env = environ.copy()
    env['ZSERVER_PORT'] = env.get('PORT1', '55000')

    start = time()

    process = Popen(
        params,
        env=env,
        stderr=PIPE,
        stdout=PIPE,
        )

    stdout, stderr = process.communicate()
    returncode = process.returncode

    runtime = time() - start

    result = {
        'layers': layers,
        'modules': modules,
        'returncode': returncode,
        'runtime': runtime,
        'stderr': stderr,
        'stdout': stdout,
        }

    logger.debug('Done: %s %s in %s', layers, modules, humanize_time(runtime))
    if DEBUG_MODE:
        # This explicitly expects UTF-8 as the runtime locale!
        if stderr:
            print(stderr.decode('UTF-8'), end='')
        if returncode:
            print(stdout.decode('UTF-8'), end='')

    return result


def handle_results(results):
    success = []

    for result in results:
        # For some reason we get the test run result dict wrapped in a list
        returncode = result.get('returncode', 1)
        stderr = result.get('stderr', None)
        stdout = result.get('stdout', None)

        if not stderr and not returncode:
            success.append(True)

        else:
            success.append(False)
            # We already printed at test runtime
            if not DEBUG_MODE:
                # This explicitly expects UTF-8 as the runtime locale!
                print(stderr.decode('UTF-8'), end='')
                if returncode:
                    print(stdout.decode('UTF-8'), end='')

    # Nothing returned False, everything went fine
    if all(r is True for r in success):
        logger.info('No failed tests.')
        exit(0)

    # Fail per default
    exit(1)


def main():
    """Discovers and times tests in parallel via multiprocessing.Pool()."""
    # Remove *.py[co] files to avoid race conditions with parallel workers
    # stepping on each other's toes when trying to clean up stale bytecode.
    #
    # Setting PYTHONDONTWRITEBYTECODE is not enough, because running buildout
    # also already precompiles bytecode for some eggs.
    logger.info('Cleaning bytecode files.')
    remove_bytecode_files(OPENGEVER_PATH)
    remove_bytecode_files('src')

    test_run_params = create_test_run_params()
    pool = Pool(CONCURRENCY)

    start = time()

    results = tuple(sorted(
        pool.map(run_tests, test_run_params),
        key=lambda result: result.get('runtime', 0.0),
        ))

    pool.close()
    pool.join()

    logger.debug(
        'Aggregate runtime %s.',
        humanize_time(sum(
            i.get('runtime', 0.0)
            for i in results
            ))
        )

    logger.debug('Wallclock runtime %s.', humanize_time(time() - start))

    handle_results(results)


# Having the __main__ guard is necessary for multiprocessing.Pool().
if __name__ == '__main__':
    # Globals
    environ['PYTHONUNBUFFERED'] = '1'
    environ['PYTHONDONTWRITEBYTECODE'] = '1'

    DEBUG_MODE = False

    CONCURRENCY = int(environ.get('MTEST_PROCESSORS', get_concurrency()))

    BUILDOUT_PATH = path.abspath(path.join(__file__, '..', '..'))
    OPENGEVER_PATH = path.join(BUILDOUT_PATH, 'opengever')

    # CLI arguments
    parser = ArgumentParser(description='Run tests in parallel.')

    parser.add_argument(
        '-d',
        '--debug',
        help='Set the log level to debug.',
        action='store_true',
        )

    parser.add_argument(
        '-j',
        '--jobs',
        help='Set the testing concurrency level.',
        )

    args = parser.parse_args()

    if args.jobs:
        CONCURRENCY = int(args.jobs)

    if args.debug:
        DEBUG_MODE = True
        default_loglevel = DEBUG
    else:
        default_loglevel = INFO

    # Logging
    logger = getLogger('mtest')
    logger.setLevel(default_loglevel)

    # Set up logging to stdout
    stream_handler = StreamHandler()
    stream_handler.setLevel(default_loglevel)
    log_formatter = Formatter(
        ' - '.join((
            '%(asctime)s',
            '%(name)s',
            '%(levelname)s',
            '%(message)s',
            )),
        )
    stream_handler.setFormatter(log_formatter)

    # Buffer log messages so we do not get broken-by-racecondition
    # debug log lines in stdout
    memory_handler = MemoryHandler(
        4096,
        flushLevel=DEBUG,
        target=stream_handler,
        )
    memory_handler.setLevel(default_loglevel)

    logger.addHandler(memory_handler)

    setup_termination()
    main()
